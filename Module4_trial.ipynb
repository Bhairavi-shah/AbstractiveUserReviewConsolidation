{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Module4_Seq2SeqModel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bhairavi-shah/AbstractiveUserReviewConsolidation/blob/master/Module4_trial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "191660aa-e837-4cad-8ece-c3755137fced",
        "id": "W8argiSZ1lCj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "#Initialise drive configurations\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/gdrive/My Drive/PROJECT | S7-S8/Colab Notebooks/')\n",
        "\n",
        "#import custom attention layer\n",
        "from attention import AttentionLayer"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5WeMBqyULqN",
        "colab_type": "code",
        "outputId": "368a24e2-b656-48bd-bfbc-99099c6644ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Import modules\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import re\n",
        "import pickle\n",
        "from bs4 import BeautifulSoup\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from google.colab import files\n",
        "import warnings\n",
        "pd.set_option(\"display.max_colwidth\", 200)\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67Vy2AHnUON9",
        "colab_type": "code",
        "outputId": "b05c96b9-3c3c-4760-faac-9ab716664728",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        }
      },
      "source": [
        "%%time\n",
        "#Read data\n",
        "data = pd.read_csv(r\"/content/gdrive/My Drive/PROJECT | S7-S8/Data/training_seq2seq.csv\")\n",
        "print(data.columns)\n",
        "print(data)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['Unnamed: 0', 'Id', 'ProductId', 'UserId', 'ProfileName',\n",
            "       'HelpfulnessNumerator', 'HelpfulnessDenominator', 'Score', 'Time',\n",
            "       'Summary', 'Text'],\n",
            "      dtype='object')\n",
            "        Unnamed: 0  ...                                                                                                                                                                                                     Text\n",
            "0           562970  ...                                                                  I love these cookies!  Not only are they healthy but they taste great and are so soft!  I will definitely add these to my grocery list!\n",
            "1           562971  ...  Quaker Soft Baked Oatmeal Cookies with raisins are a delicious treat, great for anytime of day.  For example:<br /><br />--at breakfast, I had one with a large banana and a cup of coffee, and felt...\n",
            "2           562972  ...  I am usually not a huge fan of oatmeal cookies, but these literally melt in your mouth. They are so soft and tasty! I would definitely recommend these to someone who loves oatmeal, and even those ...\n",
            "3           562973  ...  I participated in a product review that included a sample of <a href=\"http://www.amazon.com/gp/product/B007JFMH8M\">Quaker Soft Baked Oatmeal Cookie, Raisins, 8.8-Ounce (Pack of 12)</a>.  Okay firs...\n",
            "4           562974  ...                                My kids loved these. I was very pleased to give my kids a quick on the go healthy snack before soccer and acne practice. They loved the flavor, I loved that its healthy.\n",
            "...            ...  ...                                                                                                                                                                                                      ...\n",
            "134252      207087  ...  I was a huge fan of canidae, but beginning about a month ago, the company changed the formula to cheaper raw materials, smaller bags, and worst of all outsourced manufacturing to Diamond pet foods...\n",
            "134253      207088  ...                                           My dogs enjoy this food and seem lively and excited to eat it. Very happy also that it's not made by Menu Foods - peace of mind factor is high. Great product!\n",
            "134254      207089  ...                                                                            I was happy to see that I could order this product online and have it shipped to my home.  It is difficult to find in stores.\n",
            "134255      207090  ...  I bought this food for my adult male chiweenie and two female chiweeniepom puppies. I researched for a while before finally deciding to get this particular brand. I'm glad I did get this brand. My...\n",
            "134256      207091  ...  Not only does my dog love the food but it got here super quick and just in time for me to have enough food for my dog for the next month in a half or so. I have an english bulldog and it keeps him...\n",
            "\n",
            "[134257 rows x 11 columns]\n",
            "CPU times: user 697 ms, sys: 101 ms, total: 799 ms\n",
            "Wall time: 2.43 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wl9vv8FAUZ7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#dropping duplicates and na values\n",
        "data.drop_duplicates(subset=['Text'],inplace=True)\n",
        "data.dropna(axis=0,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8mLAABEUchu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJWvPeQ0Ugcz",
        "colab_type": "code",
        "outputId": "0bc6203b-1ca9-4e9d-e36c-a372b4939118",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('english')) \n",
        "\n",
        "# Preprocessing function\n",
        "def text_cleaner(text,num):\n",
        "    newString = text.lower()\n",
        "    newString = BeautifulSoup(newString, \"lxml\").text\n",
        "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
        "    newString = re.sub('\"','', newString)\n",
        "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
        "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
        "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
        "    newString = re.sub('[m]{2,}', 'mm', newString)\n",
        "    if(num==0):\n",
        "        tokens = [w for w in newString.split() if not w in stop_words]\n",
        "    else:\n",
        "        tokens=newString.split()\n",
        "    long_words=[]\n",
        "    for i in tokens:\n",
        "        if len(i)>1:                                                 #removing short word\n",
        "            long_words.append(i)   \n",
        "    return (\" \".join(long_words)).strip()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayVmuV1uUny5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#call text_cleaner function to preprocess both review and summary for training\n",
        "cleaned_text = []\n",
        "for t in data['Text']:\n",
        "    cleaned_text.append(text_cleaner(t,0)) \n",
        "\n",
        "cleaned_summary = []\n",
        "for t in data['Summary']:\n",
        "    cleaned_summary.append(text_cleaner(t,1))\n",
        "\n",
        "data['cleaned_text']=cleaned_text\n",
        "data['cleaned_summary']=cleaned_summary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K237fFRtUxIC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#drop empty rows\n",
        "data.replace('', np.nan, inplace=True)\n",
        "data.dropna(axis=0,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCBdU3e6Uzd6",
        "colab_type": "code",
        "outputId": "0e010867-d014-41b1-dd1a-7d3818648ff3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#to fix max length of the sequence\n",
        "cnt=0\n",
        "for i in data['cleaned_summary']:\n",
        "    if(len(i.split())<=15):\n",
        "        cnt=cnt+1\n",
        "print(cnt/len(data['cleaned_summary']))\n",
        "\n",
        "max_text_len=50\n",
        "max_summary_len=15"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9978761437850657\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gSj5XNyVbVY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#selecting reviews with length equal to or less than max_len\n",
        "cleaned_text =np.array(data['cleaned_text'])\n",
        "cleaned_summary=np.array(data['cleaned_summary'])\n",
        "\n",
        "short_text=[]\n",
        "short_summary=[]\n",
        "\n",
        "for i in range(len(cleaned_text)):\n",
        "    if(len(cleaned_summary[i].split())<=max_summary_len and len(cleaned_text[i].split())<=max_text_len):\n",
        "        short_text.append(cleaned_text[i])\n",
        "        short_summary.append(cleaned_summary[i])\n",
        "        \n",
        "df=pd.DataFrame({'text':short_text,'summary':short_summary})\n",
        "\n",
        "#adding start and end tokens to the data\n",
        "df['summary'] = df['summary'].apply(lambda x : 'sostok '+ x + ' eostok')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FZFbLjnVfpI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#split train and test data\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_tr,x_val,y_tr,y_val=train_test_split(np.array(df['text']),np.array(df['summary']),test_size=0.1,random_state=0,shuffle=True) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TChU5J1rVh6i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer() \n",
        "x_tokenizer.fit_on_texts(list(x_tr))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ni-yQLEsVlK0",
        "colab_type": "code",
        "outputId": "e1279757-3420-4c15-9d2c-c3c2c5dbe1c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "#find proportion of rare words in the data\n",
        "thresh=4\n",
        "\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in x_tokenizer.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "    \n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "% of rare words in vocabulary: 63.80149341387701\n",
            "Total Coverage of rare words: 2.3025567271771283\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YVBvlK7Vnoa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
        "x_tokenizer.fit_on_texts(list(x_tr))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr)\n",
        "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
        "\n",
        "#padding zero upto maximum length\n",
        "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
        "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
        "\n",
        "#size of vocabulary ( +1 for padding token)\n",
        "x_voc   =  x_tokenizer.num_words + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AA1lt-LfVp7q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prepare a tokenizer for summary on training data\n",
        "y_tokenizer = Tokenizer()   \n",
        "y_tokenizer.fit_on_texts(list(y_tr))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5q8Uf9wwVuSf",
        "colab_type": "code",
        "outputId": "8a293e93-cbfe-4871-f4f9-d062a411664b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "#find proportion of rare words in the data\n",
        "thresh=6\n",
        "\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in y_tokenizer.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "    \n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "% of rare words in vocabulary: 74.65366129488267\n",
            "Total Coverage of rare words: 4.417379107337768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvhyAvbhVwmO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prepare a tokenizer for summary on training data\n",
        "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
        "y_tokenizer.fit_on_texts(list(y_tr))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
        "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
        "\n",
        "#padding zero upto maximum length\n",
        "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
        "y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
        "\n",
        "#size of vocabulary\n",
        "y_voc  =   y_tokenizer.num_words +1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMkEbgjCV0kM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#delete rows with only start and end tokens\n",
        "ind=[]\n",
        "for i in range(len(y_tr)):\n",
        "    cnt=0\n",
        "    for j in y_tr[i]:\n",
        "        if j!=0:\n",
        "            cnt=cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "\n",
        "y_tr=np.delete(y_tr,ind, axis=0)\n",
        "x_tr=np.delete(x_tr,ind, axis=0)\n",
        "\n",
        "ind=[]\n",
        "for i in range(len(y_val)):\n",
        "    cnt=0\n",
        "    for j in y_val[i]:\n",
        "        if j!=0:\n",
        "            cnt=cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "\n",
        "y_val=np.delete(y_val,ind, axis=0)\n",
        "x_val=np.delete(x_val,ind, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8VkSyfV95JJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Save the tokenizers to be used for prediction\n",
        "#with open('text_tokenizer.pickle', 'wb') as handle:\n",
        "#    pickle.dump(x_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "#files.download('text_tokenizer.pickle')\n",
        "#with open('summary_tokenizer.pickle', 'wb') as handle:\n",
        "#    pickle.dump(y_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "#files.download('summary_tokenizer.pickle')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZFBBrUUWJd6",
        "colab_type": "code",
        "outputId": "d23ee5f2-ab5c-447e-b1e6-895713a7e707",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701
        }
      },
      "source": [
        "#from keras import backend as K\n",
        "from tensorflow.keras import backend as K\n",
        "K.clear_session()\n",
        "\n",
        "latent_dim = 300\n",
        "embedding_dim=100\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_text_len,))\n",
        "\n",
        "#embedding layer\n",
        "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
        "\n",
        "#encoder lstm 1\n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "\n",
        "#encoder lstm 2\n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "\n",
        "#encoder lstm 3\n",
        "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "#embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
        "\n",
        "# Attention layer\n",
        "attn_layer = AttentionLayer(name='attention_layer')\n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
        "\n",
        "# Concat attention input and decoder LSTM output\n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "#dense layer\n",
        "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_concat_input)\n",
        "\n",
        "# Define the model \n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.summary() "
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 50, 100)      863000      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 50, 300), (N 481200      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 50, 300), (N 721200      lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 100)    179400      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, 50, 300), (N 721200      lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 300),  481200      embedding_1[0][0]                \n",
            "                                                                 lstm_2[0][1]                     \n",
            "                                                                 lstm_2[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer (AttentionLayer ((None, None, 300),  180300      lstm_2[0][0]                     \n",
            "                                                                 lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 600)    0           lstm_3[0][0]                     \n",
            "                                                                 attention_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, None, 1794)   1078194     concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 4,705,694\n",
            "Trainable params: 4,705,694\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7wg_rqxWTo3",
        "colab_type": "code",
        "outputId": "005389a7-92c4-4e65-afce-c2db11109d40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "#compile and train the model\n",
        "filename = 'model.h5'\n",
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
        "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=100,batch_size=128, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "272/272 [==============================] - 160s 589ms/step - loss: 1.7013 - val_loss: 1.4671\n",
            "Epoch 2/100\n",
            "272/272 [==============================] - 159s 583ms/step - loss: 1.4679 - val_loss: 1.3856\n",
            "Epoch 3/100\n",
            "272/272 [==============================] - 158s 580ms/step - loss: 1.3809 - val_loss: 1.3193\n",
            "Epoch 4/100\n",
            "272/272 [==============================] - 158s 581ms/step - loss: 1.3109 - val_loss: 1.2711\n",
            "Epoch 5/100\n",
            "272/272 [==============================] - 157s 577ms/step - loss: 1.2572 - val_loss: 1.2333\n",
            "Epoch 6/100\n",
            "272/272 [==============================] - 158s 580ms/step - loss: 1.2144 - val_loss: 1.2062\n",
            "Epoch 7/100\n",
            "272/272 [==============================] - 157s 577ms/step - loss: 1.1774 - val_loss: 1.1944\n",
            "Epoch 8/100\n",
            "272/272 [==============================] - 157s 577ms/step - loss: 1.1470 - val_loss: 1.1751\n",
            "Epoch 9/100\n",
            "272/272 [==============================] - 156s 574ms/step - loss: 1.1189 - val_loss: 1.1623\n",
            "Epoch 10/100\n",
            "272/272 [==============================] - 157s 576ms/step - loss: 1.0952 - val_loss: 1.1543\n",
            "Epoch 11/100\n",
            "272/272 [==============================] - 155s 571ms/step - loss: 1.0723 - val_loss: 1.1463\n",
            "Epoch 12/100\n",
            "272/272 [==============================] - 155s 570ms/step - loss: 1.0515 - val_loss: 1.1443\n",
            "Epoch 13/100\n",
            "272/272 [==============================] - 155s 571ms/step - loss: 1.0323 - val_loss: 1.1424\n",
            "Epoch 14/100\n",
            "272/272 [==============================] - 156s 573ms/step - loss: 1.0122 - val_loss: 1.1389\n",
            "Epoch 15/100\n",
            "272/272 [==============================] - 156s 572ms/step - loss: 0.9957 - val_loss: 1.1363\n",
            "Epoch 16/100\n",
            "272/272 [==============================] - 156s 575ms/step - loss: 0.9796 - val_loss: 1.1405\n",
            "Epoch 17/100\n",
            "272/272 [==============================] - 155s 570ms/step - loss: 0.9637 - val_loss: 1.1395\n",
            "Epoch 18/100\n",
            "272/272 [==============================] - 155s 571ms/step - loss: 0.9469 - val_loss: 1.1412\n",
            "Epoch 19/100\n",
            "272/272 [==============================] - 155s 570ms/step - loss: 0.9328 - val_loss: 1.1443\n",
            "Epoch 20/100\n",
            "272/272 [==============================] - 156s 575ms/step - loss: 0.9184 - val_loss: 1.1483\n",
            "Epoch 21/100\n",
            "272/272 [==============================] - 156s 573ms/step - loss: 0.9034 - val_loss: 1.1522\n",
            "Epoch 22/100\n",
            "272/272 [==============================] - 156s 575ms/step - loss: 0.8911 - val_loss: 1.1547\n",
            "Epoch 23/100\n",
            "272/272 [==============================] - 158s 580ms/step - loss: 0.8789 - val_loss: 1.1577\n",
            "Epoch 24/100\n",
            "272/272 [==============================] - 159s 586ms/step - loss: 0.8664 - val_loss: 1.1643\n",
            "Epoch 25/100\n",
            "272/272 [==============================] - 159s 585ms/step - loss: 0.8541 - val_loss: 1.1665\n",
            "Epoch 26/100\n",
            "272/272 [==============================] - 159s 583ms/step - loss: 0.8418 - val_loss: 1.1710\n",
            "Epoch 27/100\n",
            "272/272 [==============================] - 158s 580ms/step - loss: 0.8314 - val_loss: 1.1821\n",
            "Epoch 28/100\n",
            "272/272 [==============================] - 157s 579ms/step - loss: 0.8200 - val_loss: 1.1833\n",
            "Epoch 29/100\n",
            "272/272 [==============================] - 158s 580ms/step - loss: 0.8088 - val_loss: 1.1886\n",
            "Epoch 30/100\n",
            "272/272 [==============================] - 158s 580ms/step - loss: 0.7998 - val_loss: 1.1912\n",
            "Epoch 31/100\n",
            "272/272 [==============================] - 157s 575ms/step - loss: 0.7881 - val_loss: 1.2003\n",
            "Epoch 32/100\n",
            "272/272 [==============================] - 157s 576ms/step - loss: 0.7774 - val_loss: 1.2084\n",
            "Epoch 33/100\n",
            "272/272 [==============================] - 157s 575ms/step - loss: 0.7683 - val_loss: 1.2115\n",
            "Epoch 34/100\n",
            "272/272 [==============================] - 157s 578ms/step - loss: 0.7583 - val_loss: 1.2190\n",
            "Epoch 35/100\n",
            "272/272 [==============================] - 156s 573ms/step - loss: 0.7481 - val_loss: 1.2257\n",
            "Epoch 36/100\n",
            "272/272 [==============================] - 157s 576ms/step - loss: 0.7392 - val_loss: 1.2307\n",
            "Epoch 37/100\n",
            "272/272 [==============================] - 156s 574ms/step - loss: 0.7308 - val_loss: 1.2357\n",
            "Epoch 38/100\n",
            "272/272 [==============================] - 157s 577ms/step - loss: 0.7222 - val_loss: 1.2408\n",
            "Epoch 39/100\n",
            "272/272 [==============================] - 157s 575ms/step - loss: 0.7115 - val_loss: 1.2476\n",
            "Epoch 40/100\n",
            "272/272 [==============================] - 157s 576ms/step - loss: 0.7045 - val_loss: 1.2554\n",
            "Epoch 41/100\n",
            "272/272 [==============================] - 157s 578ms/step - loss: 0.6957 - val_loss: 1.2610\n",
            "Epoch 42/100\n",
            "272/272 [==============================] - 157s 577ms/step - loss: 0.6912 - val_loss: 1.2645\n",
            "Epoch 43/100\n",
            "272/272 [==============================] - 157s 577ms/step - loss: 0.6814 - val_loss: 1.2748\n",
            "Epoch 44/100\n",
            "272/272 [==============================] - 158s 580ms/step - loss: 0.6736 - val_loss: 1.2797\n",
            "Epoch 45/100\n",
            "272/272 [==============================] - 158s 581ms/step - loss: 0.6657 - val_loss: 1.2810\n",
            "Epoch 46/100\n",
            "272/272 [==============================] - 157s 577ms/step - loss: 0.6570 - val_loss: 1.2905\n",
            "Epoch 47/100\n",
            "272/272 [==============================] - 158s 581ms/step - loss: 0.6522 - val_loss: 1.3028\n",
            "Epoch 48/100\n",
            "272/272 [==============================] - 157s 579ms/step - loss: 0.6447 - val_loss: 1.3019\n",
            "Epoch 49/100\n",
            "272/272 [==============================] - 157s 579ms/step - loss: 0.6379 - val_loss: 1.3061\n",
            "Epoch 50/100\n",
            "272/272 [==============================] - 157s 578ms/step - loss: 0.6302 - val_loss: 1.3159\n",
            "Epoch 51/100\n",
            "272/272 [==============================] - 158s 581ms/step - loss: 0.6234 - val_loss: 1.3181\n",
            "Epoch 52/100\n",
            "272/272 [==============================] - 159s 584ms/step - loss: 0.6176 - val_loss: 1.3268\n",
            "Epoch 53/100\n",
            "272/272 [==============================] - 158s 581ms/step - loss: 0.6124 - val_loss: 1.3324\n",
            "Epoch 54/100\n",
            "272/272 [==============================] - 158s 581ms/step - loss: 0.6057 - val_loss: 1.3413\n",
            "Epoch 55/100\n",
            "272/272 [==============================] - 160s 588ms/step - loss: 0.6009 - val_loss: 1.3399\n",
            "Epoch 56/100\n",
            "272/272 [==============================] - 158s 579ms/step - loss: 0.5941 - val_loss: 1.3526\n",
            "Epoch 57/100\n",
            "272/272 [==============================] - 157s 575ms/step - loss: 0.5886 - val_loss: 1.3548\n",
            "Epoch 58/100\n",
            "272/272 [==============================] - 157s 577ms/step - loss: 0.5827 - val_loss: 1.3610\n",
            "Epoch 59/100\n",
            "272/272 [==============================] - 158s 582ms/step - loss: 0.5781 - val_loss: 1.3725\n",
            "Epoch 60/100\n",
            "272/272 [==============================] - 158s 581ms/step - loss: 0.5727 - val_loss: 1.3660\n",
            "Epoch 61/100\n",
            "272/272 [==============================] - 160s 588ms/step - loss: 0.5672 - val_loss: 1.3728\n",
            "Epoch 62/100\n",
            "272/272 [==============================] - 161s 593ms/step - loss: 0.5611 - val_loss: 1.3800\n",
            "Epoch 63/100\n",
            "272/272 [==============================] - 159s 584ms/step - loss: 0.5566 - val_loss: 1.3861\n",
            "Epoch 64/100\n",
            "272/272 [==============================] - 160s 588ms/step - loss: 0.5517 - val_loss: 1.3921\n",
            "Epoch 65/100\n",
            "272/272 [==============================] - 160s 590ms/step - loss: 0.5469 - val_loss: 1.4029\n",
            "Epoch 66/100\n",
            "272/272 [==============================] - 161s 590ms/step - loss: 0.5414 - val_loss: 1.4059\n",
            "Epoch 67/100\n",
            "272/272 [==============================] - 163s 601ms/step - loss: 0.5353 - val_loss: 1.4073\n",
            "Epoch 68/100\n",
            "272/272 [==============================] - 163s 601ms/step - loss: 0.5336 - val_loss: 1.4125\n",
            "Epoch 69/100\n",
            "272/272 [==============================] - 164s 602ms/step - loss: 0.5268 - val_loss: 1.4215\n",
            "Epoch 70/100\n",
            "272/272 [==============================] - 165s 605ms/step - loss: 0.5236 - val_loss: 1.4224\n",
            "Epoch 71/100\n",
            "272/272 [==============================] - 166s 612ms/step - loss: 0.5192 - val_loss: 1.4320\n",
            "Epoch 72/100\n",
            "272/272 [==============================] - 163s 600ms/step - loss: 0.5149 - val_loss: 1.4359\n",
            "Epoch 73/100\n",
            "272/272 [==============================] - 162s 597ms/step - loss: 0.5092 - val_loss: 1.4338\n",
            "Epoch 74/100\n",
            "272/272 [==============================] - 164s 603ms/step - loss: 0.5045 - val_loss: 1.4471\n",
            "Epoch 75/100\n",
            "272/272 [==============================] - 165s 608ms/step - loss: 0.5015 - val_loss: 1.4473\n",
            "Epoch 76/100\n",
            "272/272 [==============================] - 165s 607ms/step - loss: 0.4970 - val_loss: 1.4534\n",
            "Epoch 77/100\n",
            "272/272 [==============================] - 164s 602ms/step - loss: 0.4927 - val_loss: 1.4624\n",
            "Epoch 78/100\n",
            "272/272 [==============================] - 160s 589ms/step - loss: 0.4874 - val_loss: 1.4630\n",
            "Epoch 79/100\n",
            "272/272 [==============================] - 160s 588ms/step - loss: 0.4835 - val_loss: 1.4652\n",
            "Epoch 80/100\n",
            "272/272 [==============================] - 161s 594ms/step - loss: 0.4803 - val_loss: 1.4849\n",
            "Epoch 81/100\n",
            "272/272 [==============================] - 162s 595ms/step - loss: 0.4767 - val_loss: 1.4746\n",
            "Epoch 82/100\n",
            "272/272 [==============================] - 160s 589ms/step - loss: 0.4738 - val_loss: 1.4793\n",
            "Epoch 83/100\n",
            "272/272 [==============================] - 161s 590ms/step - loss: 0.4685 - val_loss: 1.4915\n",
            "Epoch 84/100\n",
            "272/272 [==============================] - 161s 591ms/step - loss: 0.4658 - val_loss: 1.4894\n",
            "Epoch 85/100\n",
            "272/272 [==============================] - 161s 591ms/step - loss: 0.4627 - val_loss: 1.4987\n",
            "Epoch 86/100\n",
            "272/272 [==============================] - 163s 599ms/step - loss: 0.4589 - val_loss: 1.5111\n",
            "Epoch 87/100\n",
            "272/272 [==============================] - 162s 597ms/step - loss: 0.4553 - val_loss: 1.5135\n",
            "Epoch 88/100\n",
            "272/272 [==============================] - 163s 599ms/step - loss: 0.4527 - val_loss: 1.5140\n",
            "Epoch 89/100\n",
            "272/272 [==============================] - 164s 602ms/step - loss: 0.4490 - val_loss: 1.5226\n",
            "Epoch 90/100\n",
            "272/272 [==============================] - 167s 613ms/step - loss: 0.4471 - val_loss: 1.5174\n",
            "Epoch 91/100\n",
            "272/272 [==============================] - 167s 613ms/step - loss: 0.4437 - val_loss: 1.5314\n",
            "Epoch 92/100\n",
            "272/272 [==============================] - 166s 611ms/step - loss: 0.4412 - val_loss: 1.5360\n",
            "Epoch 93/100\n",
            "272/272 [==============================] - 165s 607ms/step - loss: 0.4368 - val_loss: 1.5334\n",
            "Epoch 94/100\n",
            "272/272 [==============================] - 164s 602ms/step - loss: 0.4350 - val_loss: 1.5488\n",
            "Epoch 95/100\n",
            "272/272 [==============================] - 163s 598ms/step - loss: 0.4313 - val_loss: 1.5524\n",
            "Epoch 96/100\n",
            "272/272 [==============================] - 163s 601ms/step - loss: 0.4278 - val_loss: 1.5542\n",
            "Epoch 97/100\n",
            "272/272 [==============================] - 165s 605ms/step - loss: 0.4249 - val_loss: 1.5517\n",
            "Epoch 98/100\n",
            "272/272 [==============================] - 164s 603ms/step - loss: 0.4226 - val_loss: 1.5657\n",
            "Epoch 99/100\n",
            "272/272 [==============================] - 164s 602ms/step - loss: 0.4217 - val_loss: 1.5606\n",
            "Epoch 100/100\n",
            "272/272 [==============================] - 164s 602ms/step - loss: 0.4171 - val_loss: 1.5708\n",
            "CPU times: user 6h 31min 4s, sys: 51min 17s, total: 7h 22min 22s\n",
            "Wall time: 4h 26min 53s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MQ1iJrn4qKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#save the model\n",
        "model.save(\"seq2seq.h5\")\n",
        "#files.download('seq2seq.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hf9Ux04HWbHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#dictionary to convert the index to word for target and source vocabulary\n",
        "reverse_target_word_index=y_tokenizer.index_word\n",
        "reverse_source_word_index=x_tokenizer.index_word\n",
        "target_word_index=y_tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqG0zeRcvJor",
        "colab_type": "text"
      },
      "source": [
        "**Inference Phase**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGml2fHRWgqu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode the input sequence to get the feature vector\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) \n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "#attention inference\n",
        "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_inf_concat) \n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "    [decoder_outputs2] + [state_h2, state_c2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssvjwpR8WiiB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "    \n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    \n",
        "    # Populate the first word of target sequence with the start word.\n",
        "    target_seq[0, 0] = target_word_index['sostok']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "      \n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "        \n",
        "        if(sampled_token!='eostok'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "        # Exit condition: either hit max length or find stop word.\n",
        "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TDBdJhgWlJj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
        "            newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7H6jxgYWnW5",
        "colab_type": "code",
        "outputId": "6380d4f3-6abe-48ee-e603-a16abb048b1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Testing\n",
        "for i in range(0,100):\n",
        "    print(\"Review:\",seq2text(x_tr[i]))\n",
        "    print(\"Original summary:\",seq2summary(y_tr[i]))\n",
        "    print(\"Predicted summary:\",decode_sequence(x_tr[i].reshape(1,max_text_len)))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review: tried almost happy baby flavors honestly say one daughter favorite flavor brand wish package slightly larger able finish moments sometimes wants second \n",
            "Original summary: our favorite happy baby flavor \n",
            "Predicted summary:  our favorite happy baby loves it\n",
            "\n",
            "\n",
            "Review: illy issimo coffee drink cappuccino treat hard day away computer filled tall glass crushed ice poured smooth creamy cappuccino sipped away actually took break feet settling back chair closing eyes rich coffee cocoa goodness ate ice \n",
            "Original summary: delicious treat only calories \n",
            "Predicted summary:  coffee for cold cappuccino coffee drink\n",
            "\n",
            "\n",
            "Review: love nuts tired snack bars oats featured ingredients much sugary sweet packed big crunchy chunks honey roasted peanuts almonds cashews enough rice granola together perfect balance sweet salty love first bite bar calories fiber protein fat sugar cholesterol carbs \n",
            "Original summary: yes these are really good \n",
            "Predicted summary:  snack bar\n",
            "\n",
            "\n",
            "Review: goji berries great tasting snack pack healthy punch per serving berries contain vit vit iron protein diverse nutrition call eater compare nutrition raisins never go back \n",
            "Original summary: great tasting snack \n",
            "Predicted summary:  great tasting goji berries\n",
            "\n",
            "\n",
            "Review: little cups perfect compliment cup varieties use coffees loose teas disappointed much easier use cups sold keurig \n",
            "Original summary: great substitute \n",
            "Predicted summary:  great substitute\n",
            "\n",
            "\n",
            "Review: diagnosed gluten intolerance recently loss could eat enjoy upon discovering pamela baking mix pleasantly surprised could make gluten free pancakes pound cake pumpkin bread family enjoyed eating happy found product many mixes versatile relatively inexpensive pamela mix also lasts buy yet another mix every time turn around highly recommend product \n",
            "Original summary: great place to start \n",
            "Predicted summary:  great baking mix\n",
            "\n",
            "\n",
            "Review: convenient probably good water straight coconut disappointed almost complete lack coconut flavor real substitute getting water real fresh coconut definitely better gatorade artificial electrolyte drinks \n",
            "Original summary: not much coconut flavor \n",
            "Predicted summary:  like coconut water\n",
            "\n",
            "\n",
            "Review: coconut oil fantastic high quality smells really great amazon best prices anything similar definitely get \n",
            "Original summary: wonderful \n",
            "Predicted summary:  wonderful\n",
            "\n",
            "\n",
            "Review: amazing cookie thought going gross took bite amazed please try regret \n",
            "Original summary: yum \n",
            "Predicted summary:  yum\n",
            "\n",
            "\n",
            "Review: yummy great everyday coffee newman products general wonderful earth cup jet fuel cups enough \n",
            "Original summary: yummy \n",
            "Predicted summary:  yummy\n",
            "\n",
            "\n",
            "Review: giving cat medication little year hate open mouth dropping pill get one treats ready beforehand attention treat instead pill give medication immediately give treat used run hide every time opened pill case least sticks around makes easier \n",
            "Original summary: need help giving your cat try these \n",
            "Predicted summary:  pill pockets\n",
            "\n",
            "\n",
            "Review: know come sugar diet sweet peanut flavor noticable family enjoyed cereal boxes gone many weeks think buy sugar content \n",
            "Original summary: nutty and sweet \n",
            "Predicted summary:  nutty and tasty\n",
            "\n",
            "\n",
            "Review: product recommended neighbor good healthy chew would help clean dog teeth loves \n",
            "Original summary: dog chews \n",
            "Predicted summary:  dog chews\n",
            "\n",
            "\n",
            "Review: first happybellies oatmeal cream colored odorless second brown smelled rancid third also brown color smelled little less rancid serious quality issues considering high price brand image recommend oatmeal resolve issue \n",
            "Original summary: problems with batch \n",
            "Predicted summary:  problems with batch\n",
            "\n",
            "\n",
            "Review: love big tub yummy lollipops organic price good \n",
            "Original summary: yummy pops \n",
            "Predicted summary:  yummy earth organic lollipops\n",
            "\n",
            "\n",
            "Review: good things said reviewers opened email amazon inviting review recent purchase would know husband cooking speak add raisins cinnamon walnuts little milk rice dream breakfast someone else said indeed hearty used savory meal try adding unflavored yogurt along sauteed onions tomatoes \n",
            "Original summary: great food \n",
            "Predicted summary:  first natural food\n",
            "\n",
            "\n",
            "Review: great product use cooking smoothies flavor wonderful always seems bring natural flavors meat seafood also helped control lose weight weighed lbs beginning year proper diet exercise spoonful coconut oil daily lost lbs want cut salt sugar diet taste try cooking coconut oil enhance flavors food help fix nasty cravings \n",
            "Original summary: for coconut oil \n",
            "Predicted summary:  for coconut oil\n",
            "\n",
            "\n",
            "Review: wife bought keurig started experimenting coffees strong breakfast blend hit right head course matter personal taste like coffee strong starbucks typically great coffee love keurig \n",
            "Original summary: great coffee \n",
            "Predicted summary:  best new cup\n",
            "\n",
            "\n",
            "Review: ok dark roast coffee pods found brands prefer \n",
            "Original summary: ok pods \n",
            "Predicted summary:  ok pods but ok pods\n",
            "\n",
            "\n",
            "Review: cannot caffeine use coffee good great think lack caffeine like better decafs tried \n",
            "Original summary: not my choice \n",
            "Predicted summary:  best coffee ever\n",
            "\n",
            "\n",
            "Review: found great product mother milk production started oz per time pumped get oz every time pump baby enjoys mom milk started teas per day take per day keep milk production great product \n",
            "Original summary: great product \n",
            "Predicted summary:  great product\n",
            "\n",
            "\n",
            "Review: absolutely love coconut oil delicious oatmeal even use coffee put small jar use moisturizer night niece uses instead great nephew coconut oil good particular coconut oil highly recommended \n",
            "Original summary: awesome \n",
            "Predicted summary:  awesome\n",
            "\n",
            "\n",
            "Review: warning even make food another company look back bag even list made says guaranteed canidae asked made either completely ignored given huge run around thing ever got state made would even tell dangerous pet food recalls happened years ago manufacturing \n",
            "Original summary: warning \n",
            "Predicted summary:  health\n",
            "\n",
            "\n",
            "Review: nutiva coconut oil favorite coconut oil subtle distinct coconut flavor adds something every dish use baking cooking eggs almost anything maybe next try making popcorn \n",
            "Original summary: yummy coconut \n",
            "Predicted summary:  great coconut oil\n",
            "\n",
            "\n",
            "Review: twists wonderfully soft chewy stick teeth good way however mix licorice pomegranate flavor strangely medicinal twists really sweet enough tastes still bit addictive makes impossible give one star rating \n",
            "Original summary: great texture lousy flavor \n",
            "Predicted summary:  great texture lousy flavor\n",
            "\n",
            "\n",
            "Review: tea delicious got quite lot tea fraction cost pay regularly keep good work offering great deals \n",
            "Original summary: tea \n",
            "Predicted summary:  tea\n",
            "\n",
            "\n",
            "Review: pack excellent value great take traveling use home great flavor coffees \n",
            "Original summary: excellent coffee and value \n",
            "Predicted summary:  good value and excellent coffee\n",
            "\n",
            "\n",
            "Review: mix makes great waffles crispy outside inside using presto flip side waffle maker make sure pour enough batter make full waffle til batter starts touch sides waffle maker definitely order mine runs \n",
            "Original summary: delicious waffles \n",
            "Predicted summary:  the only waffles ever\n",
            "\n",
            "\n",
            "Review: bars lack toxic substances often trigger headaches migraines taste excellent provide great amount nutrition antioxidants highly recommend product certainly adding overall healthy diet sorry purchase product \n",
            "Original summary: taste great and very healthy \n",
            "Predicted summary:  taste great and very healthy\n",
            "\n",
            "\n",
            "Review: st lime simple good clif bars loaded banana nut date end \n",
            "Original summary: healthy banana is another winner \n",
            "Predicted summary:  banana nut bread bars\n",
            "\n",
            "\n",
            "Review: favorite one italian used drink coffee also italy one prefer morning lunch dinner coffee make typical italian coffee machine called moka bialetti try believe \n",
            "Original summary: the real taste of an italian coffee \n",
            "Predicted summary:  just my italian coffee this coffee\n",
            "\n",
            "\n",
            "Review: bad bottle water received sample pleasant enough taste unpleasant taste \n",
            "Original summary: good simple water \n",
            "Predicted summary:  not what you want\n",
            "\n",
            "\n",
            "Review: best cappuccino get keurig love like taste cappuccino never get taste home solve problem think pleased purchase \n",
            "Original summary: cappuccino for keurig \n",
            "Predicted summary:  cappuccino for keurig\n",
            "\n",
            "\n",
            "Review: illy issimo coffee drink coffee flavor really love coffee drink said love coffee great served cold caffeine buzz tremendous personally could live without coffee drinkers love better choice energy drink soda based poisons \n",
            "Original summary: hope you love coffee \n",
            "Predicted summary:  delicious\n",
            "\n",
            "\n",
            "Review: product description currently states nuts hint pepper believe least much pepper salt much cannot taste anything pepper eat salty thirsty afterwards terrible product company needs seriously scale back seasonings \n",
            "Original summary: like of pepper \n",
            "Predicted summary:  like cashews\n",
            "\n",
            "\n",
            "Review: favorite cup gloria jean hazelnut tried brands preferred always \n",
            "Original summary: hazelnut our favorite \n",
            "Predicted summary:  hazelnut our favorite\n",
            "\n",
            "\n",
            "Review: recently moved back parents since little one still puppy tried parents dogs years tried many different products continue come back since dogs seem find favorite lb bag last two chihuahuas would recommend product anyone dogs \n",
            "Original summary: this product is approved \n",
            "Predicted summary:  this stuff is great for canidae\n",
            "\n",
            "\n",
            "Review: others reviewers mentioned really stink however dog seems like odor good training careful bring dog park quickly develop fans \n",
            "Original summary: smelly but good \n",
            "Predicted summary:  good but not my dog\n",
            "\n",
            "\n",
            "Review: must staple home tastes great nice quick go days regrets auto shipped monthly home \n",
            "Original summary: gluten free and cheese \n",
            "Predicted summary:  gluten free treats\n",
            "\n",
            "\n",
            "Review: small salty taste good strong good thing package contains small amount takes little crisps cure salty crunchy craving snack one package entire day course would good snack hungry enough fill less per pack okay deal \n",
            "Original summary: not bad \n",
            "Predicted summary:  great taste\n",
            "\n",
            "\n",
            "Review: noodles look like lab almost threw opened package came filled water burp gag gave away \n",
            "Original summary: me with \n",
            "Predicted summary:  these are horrible\n",
            "\n",
            "\n",
            "Review: soft cookie fan cookies fit bill nice chewy best super chocolately big okay flavor rich could eat lot time decadent snack perfect kids loved like soft chewy cookies chocolate disappointed chips ahoy chewy gooey megafudge cookies \n",
            "Original summary: decadent \n",
            "Predicted summary:  quaker soft baked oatmeal cookie\n",
            "\n",
            "\n",
            "Review: using senseo douwe egberts colombia blend coffee pods year great coffee great taste use senseo coffee maker bunn single cup coffee maker pods work well either unit recommended coffee friends \n",
            "Original summary: great coffee \n",
            "Predicted summary:  coffee lover\n",
            "\n",
            "\n",
            "Review: baby worked great couple months machine started leaking grease food made stomach turn think giving son food grease bought machine want give son baby food jar know eating disappointed also searched see people problem one ended buying blender stovetop steamer \n",
            "Original summary: grease \n",
            "Predicted summary:  grease\n",
            "\n",
            "\n",
            "Review: stumbled upon great coffee might say morning blend family friends think best yet \n",
            "Original summary: san francisco bay morning blend cups \n",
            "Predicted summary:  san francisco bay breakfast blend cups\n",
            "\n",
            "\n",
            "Review: like graham crackers love golden honey oat grahams light crisp subtly flavored satisfying \n",
            "Original summary: delicious \n",
            "Predicted summary:  delicious\n",
            "\n",
            "\n",
            "Review: product rocks like coffee shop right home without pay lot \n",
            "Original summary: coffee shop at home \n",
            "Predicted summary:  coffee shop at home\n",
            "\n",
            "\n",
            "Review: reading reviews decided give try disappointed reviews said sweet sweet yet mine tart know forget put sugar cherries \n",
            "Original summary: do they forget to put sugar into my cherries \n",
            "Predicted summary:  do not like sugar into cherries\n",
            "\n",
            "\n",
            "Review: chamomile nights tea stash delicious relaxing wonderful way end day trouble finding stores amazon carries stock great price thank amazon \n",
            "Original summary: excellent tea \n",
            "Predicted summary:  delicious tea\n",
            "\n",
            "\n",
            "Review: tried flavors switch think one favorite flavor much better red bull rockstar consumed fair share years like carbonated fruit drink energy drink definitely purchasing switch beverages like flavors tried far tired way energy drinks taste maybe time make switch \n",
            "Original summary: switch things up with this tasty energy drink \n",
            "Predicted summary:  switch with this flavor\n",
            "\n",
            "\n",
            "Review: awesome though gluten free taste better regular pretzels crunchier bad aftertaste anything taste buttery thing make sure put leftovers sealed bag else get stale quickly overall awesome \n",
            "Original summary: delicious crunchy \n",
            "Predicted summary:  tastes great with new higher sugar alternative\n",
            "\n",
            "\n",
            "Review: really makes feel good become hard drink sometimes due graininess product blended though easier swallow pain put shaker shake good seconds still grainy residue maybe normal regardless gave five stars says gives energy makes feel great auto ship program better cost \n",
            "Original summary: great makes me feel good but little \n",
            "Predicted summary:  great but very filling\n",
            "\n",
            "\n",
            "Review: bitter taste like anything found coffee shop buy \n",
            "Original summary: jet fuel \n",
            "Predicted summary:  wolfgang puck\n",
            "\n",
            "\n",
            "Review: pretty good product fresh good smell decent price subscribe save using second batch bottles still like \n",
            "Original summary: pretty good \n",
            "Predicted summary:  pretty good\n",
            "\n",
            "\n",
            "Review: wish would read reviews ordered sampler issue many others mine flavor two flavors even list eggnog gingerbread clearly leftover holiday season knows old like many others understand cannot get one everything could would wonderful pre packaged different ones selections listed \n",
            "Original summary: not sampler \n",
            "Predicted summary:  assortment get variety\n",
            "\n",
            "\n",
            "Review: pleased contains cannot use say ordering plan returning \n",
            "Original summary: cider cups \n",
            "Predicted summary:  cider cups\n",
            "\n",
            "\n",
            "Review: dog goes crazy touch virbac dog chews chewer fact chew means must taste really good expensive dog eat worth cost \n",
            "Original summary: happy dog happy customer \n",
            "Predicted summary:  happy customer\n",
            "\n",
            "\n",
            "Review: rocky looks forward getting chews hope helping oral hygiene \n",
            "Original summary: loves the chews \n",
            "Predicted summary:  loves it\n",
            "\n",
            "\n",
            "Review: love almond joy candy bars like coconut love sinfully healthy snack bar delicious forget eating healthy highly recommend tasty treat \n",
            "Original summary: better than an almond joy bar \n",
            "Predicted summary:  cannot keep an almond bar without almond and almond snack\n",
            "\n",
            "\n",
            "Review: really teeth dogs love works great big dog price get stars \n",
            "Original summary: dogs love these and can see difference \n",
            "Predicted summary:  great treats\n",
            "\n",
            "\n",
            "Review: drank least different kcup flavors timothy diedrich green mountain gloria jean van houtte think one best unlike reviewers really like aroma taste seems medium flavorful roast reviews would recommend try hated flavors many enjoy good reviews \n",
            "Original summary: one of the better kcup coffees \n",
            "Predicted summary:  as good as the starbucks\n",
            "\n",
            "\n",
            "Review: ok admit bit particular tea tea hits spot makes stand good teas good flavour rounded taste never bitter definitely recommended count boxes really makes excellent deal \n",
            "Original summary: strong but not with bitter aftertaste \n",
            "Predicted summary:  strong with strong with flavor\n",
            "\n",
            "\n",
            "Review: lucky enough serve coffee wonderful thanksgiving meal cheers around gevalia smooth little bitterness wonderful aroma taste chocolate truffle flavor good overwhelming plain others added milk made flavor bit creamy gevalia put freezer storage great coffee guests gift \n",
            "Original summary: smooth and yummy \n",
            "Predicted summary:  smooth and mild\n",
            "\n",
            "\n",
            "Review: bar little salty taste little hard chew bars tried kind much better little disappointing \n",
            "Original summary: too hard and too salty \n",
            "Predicted summary:  too salty\n",
            "\n",
            "\n",
            "Review: taste bitter bad way coffee taste bitter smooth one hint vanilla flavor coffee aroma tried different way make coffe matter taste bad \n",
            "Original summary: no matter what do it still taste bad \n",
            "Predicted summary:  bit disappointed\n",
            "\n",
            "\n",
            "Review: dog loves treats great quality cheaper buying big box stores really cannot go wrong \n",
            "Original summary: cannot go wrong \n",
            "Predicted summary:  cannot go wrong\n",
            "\n",
            "\n",
            "Review: purchased timothy breakfast blend cups wife breakfast blend favorite coffee choice one coffee selections supplies keurig brewers judge taste timothy brand good green mountain brand provided tried concur taste bad good however price per cup timothy brand attractive us case one gets one pays \n",
            "Original summary: timothy breakfast blend \n",
            "Predicted summary:  timothy breakfast blend\n",
            "\n",
            "\n",
            "Review: really nice beans folks came moist aromatic made really delicious vanilla pop make bottles give gifts everyone loves bottle vanilla present \n",
            "Original summary: great beans \n",
            "Predicted summary:  vanilla beans\n",
            "\n",
            "\n",
            "Review: ordered product hoping finally found healthy substitute peanut butter boy wrong vile thing ever tasted smell alone enough make stomach actually took bite started gagging horrible would never order however heard walden farms products bad tried yet plan trying eventually \n",
            "Original summary: no thank you \n",
            "Predicted summary:  these no amazon no no\n",
            "\n",
            "\n",
            "Review: made share banana nut breads quaker version hand convenient enjoy anytime wanted definitely delicious received complimentary influenster mom voxbox buy items next grocery shopping \n",
            "Original summary: banana nut bread anytime \n",
            "Predicted summary:  so delicious\n",
            "\n",
            "\n",
            "Review: love coconut water usually stay away flavored options tried fluke airport thought delicious tastes similar yoohoo familiar drink quite refreshing taste think plain coconut water definitely tasty beverage find enjoyable like chocolate good beverage \n",
            "Original summary: wow \n",
            "Predicted summary:  wow\n",
            "\n",
            "\n",
            "Review: nice different tea sweet flavorful although says blackberry vanilla neither flavor overwhelming brews readily actually get probably cup half one teabag really like new tea bags seem get flavor quicker old style teabags probably buy tea prefer regular tea stronger flavor tea would nice someone looking flavorful non caffeinated tea \n",
            "Original summary: nice flavor not too sweet \n",
            "Predicted summary:  not bad not great\n",
            "\n",
            "\n",
            "Review: first purchased cookies local health food store fell love crispy outside chewy inside heaven decided purchase amazon since cost effective pretty disappointed tasted old crumbly advice find store carries pay extra money worth \n",
            "Original summary: better from the store \n",
            "Predicted summary:  delicious\n",
            "\n",
            "\n",
            "Review: getting teas herbal teas past tasted like drinking grass yuck recently bought tea honestly say like buy personally add little milk stevia sweetener also like jasmine tea make \n",
            "Original summary: good tea \n",
            "Predicted summary:  great tea\n",
            "\n",
            "\n",
            "Review: oh thinking buying nasty texture like chewing flesh bounces teeth away bite also smells weird thought good true made nervous swallow like nasty thing edible food sorry people make stuff ill hate \n",
            "Original summary: if could give it stars would nasty \n",
            "Predicted summary:  if could give it stars would nasty\n",
            "\n",
            "\n",
            "Review: shocked see great reviews product admittedly used mix make pancakes good hesitant try making anything else love bob red mill gluten free pancake mix recommend pamela \n",
            "Original summary: does not make good pancakes \n",
            "Predicted summary:  more pancakes pancakes\n",
            "\n",
            "\n",
            "Review: ordered taco bell chipotle sauce amazon vine put sauce taco bell tacos burritos thought sauce good tasted strong lot spices thicker sauce restaurant thin must many spices wife thought ok found smoky flavor thought tangy flavor john \n",
            "Original summary: it is good sauce \n",
            "Predicted summary:  good for taco salad recommended\n",
            "\n",
            "\n",
            "Review: flavor best tried far get sick drinking almost first lbs ready reorder flavor tried orange nothing use cytomax need wash clumpy gels try mixing two bottles freezing one tasty treat one hour long bike ride \n",
            "Original summary: great flavor throw out the \n",
            "Predicted summary:  great is too bad\n",
            "\n",
            "\n",
            "Review: taste good healthy low carbs great snack sometimes crunch meal replacement said last shipment amazon good chocolate bloomed taste quite good means warehouse kept probably temperature lot thinkthin bought bars years know else post comment otherwise really even take vacation \n",
            "Original summary: kind of cannot live without them \n",
            "Predicted summary:  kind of cannot live without them\n",
            "\n",
            "\n",
            "Review: went virtually every bold dark coffee keurig emerils big easy bold best dark coffee class slightest way bitter pack great bargain \n",
            "Original summary: emeril big easy bold \n",
            "Predicted summary:  emeril big easy bold cups\n",
            "\n",
            "\n",
            "Review: cookies pamelas simplebites products truly amazing searching forever even decent tasting gluten free cookie incredible possibly even better regular cookies let fooled regular sized pamelas cookies like much love \n",
            "Original summary: amazing \n",
            "Predicted summary:  amazing cookies\n",
            "\n",
            "\n",
            "Review: really like taste powder great protein shake especially banana blended issue shelf life product oz container lasts long time container purchased amazon expired less month purchase date noticed date production exactly year ago protein powders shelf life couple years \n",
            "Original summary: very good in smoothies but why the short life \n",
            "Predicted summary:  very good in smoothies\n",
            "\n",
            "\n",
            "Review: popcorn rivals movie theaters even call people selling movie theater popcorn cannot hold popcorn \n",
            "Original summary: great taste \n",
            "Predicted summary:  great taste\n",
            "\n",
            "\n",
            "Review: previously couple flavors switch beverages liked good bit one bad certainly kiwi flavor prominent really try distinguish kiwi flavor berry tasted since would like flavors well expecting would like one well even bother finishing drink people might like better found sweet worthy drinking \n",
            "Original summary: mediocre beverage \n",
            "Predicted summary:  mediocre beverage\n",
            "\n",
            "\n",
            "Review: coffee good amount green mountain coffee hoping donut house coffee people brown paper bags comes coffee still tastes good \n",
            "Original summary: good coffee but would like bit more variety \n",
            "Predicted summary:  not good coffee\n",
            "\n",
            "\n",
            "Review: stuff delicious healthy currently use fresh fruit salad painful truth america sick \n",
            "Original summary: live food syrup \n",
            "Predicted summary:  live food syrup\n",
            "\n",
            "\n",
            "Review: dark chocolate person found particular chocolate little bitter side probably good baking however sure would buy regular consumption \n",
            "Original summary: rich but little bitter \n",
            "Predicted summary:  rich but little bitter\n",
            "\n",
            "\n",
            "Review: really enjoyed item appletini flavor quite tasty easy mix taste like actual appletini came close even expert would notice difference finally new crystal light flavor us taste something different \n",
            "Original summary: great item \n",
            "Predicted summary:  too sweet for me\n",
            "\n",
            "\n",
            "Review: bought mostly putting protein shakes without calories let tell stuff amazing bought chocolate pb eat dry water shakes toast good really putting shakes using dessert would recommend even price \n",
            "Original summary: omg like \n",
            "Predicted summary:  more like peanut butter\n",
            "\n",
            "\n",
            "Review: ok flavorful like maybe son tried liked hazel nutty like try maybe st cup dud \n",
            "Original summary: ok but not as flavorful as like \n",
            "Predicted summary:  ok but not as flavorful as they\n",
            "\n",
            "\n",
            "Review: wanted pup love week old yorkshire terrier seem interested maybe bit older mean product seems great pup like em \n",
            "Original summary: eh \n",
            "Predicted summary:  eh\n",
            "\n",
            "\n",
            "Review: insanely hot give idea one dime size amount sauce enough bring serious heat whole chicken high tolerance spicy food usually inhale whole bottle sauce within week put everything eat sauce six months used less tablespoon advice make sure glass milk right along side sauce oh yeah start small \n",
            "Original summary: not for \n",
            "Predicted summary:  not for\n",
            "\n",
            "\n",
            "Review: look price small bags dried cherries grocery store market realize great bargain pound box really cherries great semi tart flavor good color excellent baking snack \n",
            "Original summary: premium cherries \n",
            "Predicted summary:  greenies are like out of\n",
            "\n",
            "\n",
            "Review: tongue hurts ate first haribo gummy bears tongue hurts several raised sores end shocked read packaging noticed artificial flavors colors yuck would known would purchased see information amazon website guess away good reviews read carefully enough ouch \n",
            "Original summary: artificial and flavors \n",
            "Predicted summary:  made in china\n",
            "\n",
            "\n",
            "Review: cup explode strained coffee tasted tasted like water pool \n",
            "Original summary: do not buy be \n",
            "Predicted summary:  do not buy\n",
            "\n",
            "\n",
            "Review: stuff terrible took one spoonful taste right bought threw away tasted nothing like peanut butter like idea even low fat peanut butter still tons fat even edible butter options low fat still taste good \n",
            "Original summary: would give it zero stars if possible \n",
            "Predicted summary:  would give it zero stars if possible\n",
            "\n",
            "\n",
            "Review: delicious graham crackers divided convenient portions love graham crackers love portion size great packing lunch box said care needed crackers pretty fragile places brown paper bag could end conveniently portion graham crumbs packing hard lunch box careful packed lunch way go \n",
            "Original summary: delicious snack in convenient portions \n",
            "Predicted summary:  delicious snack in convenient portions\n",
            "\n",
            "\n",
            "Review: giving pills daily basis animal shelter found provide advantage either breaking pill mixing canned food pushing pill chunk meat dogs eat pill pocket away pill leave pill untouched suggest mixing pills something strong odor flavor one trick push pill bit hotdog dog resist \n",
            "Original summary: ok product but \n",
            "Predicted summary:  the best but not the best\n",
            "\n",
            "\n",
            "Review: made noodles classic fine nothing rave yes made brown rice somewhat healthier enough buy frankly non wheat noodles always pure white rice vermicelli enough vegetables protein need added little boost brown rice noodles \n",
            "Original summary: ok \n",
            "Predicted summary:  ok\n",
            "\n",
            "\n",
            "Review: like hot cold think best food diabetics amazon price cheapest buy product nutrition label however may wrong sodium listed mg correct since item includes whole grain oats wheat rye almonds walnuts flaxseed contain sodium natural form \n",
            "Original summary: the ideal food \n",
            "Predicted summary:  the lab of the gf baby chews\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExG4iIis1vdO",
        "colab_type": "code",
        "outputId": "0439065c-05c6-458d-d6ad-c9fbfcea3654",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "%%time\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "def sum_extract(all_summaries):\n",
        "  article_text = all_summaries\n",
        "  formatted_article_text = all_summaries\n",
        "  sentence_list = nltk.sent_tokenize(article_text)\n",
        "  stopwords = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "  word_frequencies = {}\n",
        "  for word in nltk.word_tokenize(formatted_article_text):\n",
        "      if word not in stopwords:\n",
        "          if word not in word_frequencies.keys():\n",
        "              word_frequencies[word] = 1\n",
        "          else:\n",
        "              word_frequencies[word] += 1\n",
        "\n",
        "  maximum_frequncy = max(word_frequencies.values())\n",
        "\n",
        "  for word in word_frequencies.keys():\n",
        "      word_frequencies[word] = (word_frequencies[word]/maximum_frequncy)\n",
        "\n",
        "  sentence_scores = {}\n",
        "  for sent in sentence_list:\n",
        "      for word in nltk.word_tokenize(sent.lower()):\n",
        "          if word in word_frequencies.keys():\n",
        "              if len(sent.split(' ')) < 30:\n",
        "                  if sent not in sentence_scores.keys():\n",
        "                      sentence_scores[sent] = word_frequencies[word]\n",
        "                  else:\n",
        "                      sentence_scores[sent] += word_frequencies[word]\n",
        "\n",
        "  import heapq\n",
        "  summary_sentences = heapq.nlargest(5, sentence_scores, key=sentence_scores.get)\n",
        "\n",
        "  summary = ' '.join(summary_sentences)\n",
        "  print(summary)\n",
        "  return(summary)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "CPU times: user 289 ms, sys: 47.2 ms, total: 336 ms\n",
            "Wall time: 457 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEBESd823976",
        "colab_type": "code",
        "outputId": "84cd931c-7784-42f4-9c8c-d3714be85605",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "%%time\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth',1000)\n",
        "\n",
        "import nltk\n",
        "import pickle\n",
        "import re, string, random\n",
        "from nltk.tag import pos_tag\n",
        "from google.colab import files\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.corpus import twitter_samples, stopwords\n",
        "from nltk import FreqDist, classify, NaiveBayesClassifier\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('twitter_samples')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import urllib3\n",
        "import json\n",
        "http=urllib3.PoolManager()\n",
        "Abbr_dict={}\n",
        "\n",
        "#Function to get the Slangs from https://www.noslang.com/dictionary/\n",
        "def getAbbr(alpha):\n",
        "    global Abbr_dict\n",
        "    r=http.request('GET','https://www.noslang.com/dictionary/'+alpha)\n",
        "    soup=BeautifulSoup(r.data,'html.parser')\n",
        "    \n",
        "    for i in soup.findAll('div',{'class':'dictionary-word'}): \n",
        "\n",
        "        abbr=i.find('abbr')['title']\n",
        "        Abbr_dict[i.find('span').text[:-2]]=abbr\n",
        "\n",
        "#Generating a-z\n",
        "linkDict=[]\n",
        "for x in range(97,123):\n",
        "    linkDict.append(chr(x))\n",
        "\n",
        "#Creating Links for https://www.noslang.com/dictionary/a...https://www.noslang.com/dictionary/b....etc\n",
        "for i in linkDict:\n",
        "    getAbbr(i)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "CPU times: user 2.75 s, sys: 209 ms, total: 2.96 s\n",
            "Wall time: 12.5 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KASGIPlg31sT",
        "colab_type": "code",
        "outputId": "52fddc93-f289-4fb4-fcba-287037fa77cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "%%time\n",
        "def remove_noise(tweet_tokens, stop_words = ()):\n",
        "  cleaned_tokens = []\n",
        "  for token, tag in pos_tag(tweet_tokens):\n",
        "    token = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+#]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+','', token)\n",
        "    token = re.sub(\"(@[A-Za-z0-9_]+)\",\"\", token)\n",
        "    if token in Abbr_dict.keys():\n",
        "      token = Abbr_dict[token]\n",
        "    if tag.startswith(\"NN\"):\n",
        "      pos = 'n'\n",
        "    elif tag.startswith('VB'):\n",
        "      pos = 'v'\n",
        "    else:\n",
        "      pos = 'a'\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    token = lemmatizer.lemmatize(token, pos)\n",
        "    if len(token) > 0 and token not in string.punctuation and token.lower() not in stop_words:\n",
        "      cleaned_tokens.append(token.lower())\n",
        "  return cleaned_tokens"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
            "Wall time: 5.72 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNJq7H3g2_vY",
        "colab_type": "code",
        "outputId": "551ee2f0-5475-4ca4-82a7-8ba16c23f107",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "%%time\n",
        "import pandas as pd\n",
        "pickle_in = open(r\"/content/gdrive/My Drive/PROJECT | S7-S8/Pickle Files/nb_sentiment_analysis_final.pkl\",\"rb\")\n",
        "classifier = pickle.load(pickle_in)\n",
        "def pred_sentiment(sum_text):\n",
        "  sum_text = remove_noise(word_tokenize(sum_text))\n",
        "  sentiment = classifier.classify(dict([tok, True] for tok in sum_text))\n",
        "  return(sentiment)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 330 ms, sys: 2.53 ms, total: 333 ms\n",
            "Wall time: 2.18 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLOAK_JI4RsG",
        "colab_type": "code",
        "outputId": "46ed2978-b0ba-4037-a741-427af4943989",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "from gensim.summarization.summarizer import summarize \n",
        "from gensim.summarization import keywords\n",
        "data = pd.read_csv(r\"/content/gdrive/My Drive/PROJECT | S7-S8/Data/testing_seq2seq.csv\")\n",
        "meta_data = pd.read_json(\"/content/gdrive/My Drive/PROJECT | S7-S8/Data/product_details (1).json\")\n",
        "\n",
        "#dropping duplicates and na values\n",
        "data.drop_duplicates(subset=['Text'],inplace=True)\n",
        "data.dropna(axis=0,subset=['Text'], inplace=True)\n",
        "\n",
        "#call text_cleaner function to preprocess both review and summary for training\n",
        "cleaned_text = []\n",
        "for t in data['Text']:\n",
        "    cleaned_text.append(text_cleaner(t,0)) \n",
        "\n",
        "data['cleaned_text']=cleaned_text\n",
        "\n",
        "data.replace('', np.nan, inplace=True)\n",
        "data.dropna(axis=0,inplace=True)\n",
        "\n",
        "res_df = pd.DataFrame(columns=['pid', 'title', 'summaries', 'avg_rating', 'sentiment'])\n",
        "\n",
        "j = 0\n",
        "\n",
        "pid_test = ['B000CQE3NM', 'B001L4JH5I', 'B003EM7J9Q', 'B000CQID2Y', 'B005K4Q1T0', 'B000DZFMEQ', 'B001GL6GBE', 'B003CK7O36', 'B003QNJYXM', 'B000ZSZ5S4', 'B001EO5Y8Y', 'B000CQC08C', 'B0039ZOZ86', 'B005K4Q37A', 'B000REI2X6', 'B000PDY3P0', 'B005ZBZLSU', 'B002GJ9JY6', 'B006N3HYYS', 'B000CQIDHY', 'B001E5E3JY', 'B000F6SNPS', 'B005ZBZLT4', 'B000CQIDHO', 'B0008IT4OM', 'B003CK2BQG', 'B000ESLJ6C', 'B000HDK0DC', 'B001EYUE5M', 'B005DFL4PM', 'B001CWX7EG', 'B000DZDJ0K', 'B000CQBZOW', 'B004SRH2B6', 'B005GX00BK', 'B007TJGZ5E', 'B008ZRKZSM', 'B000CQG8KS', 'B000CQC05K', 'B0058AMYTC', 'B005HG9ESG', 'B000GAT6NG', 'B000CQIDHE', 'B000WB1YSE', 'B0012BUR8Q', 'B0098WV8F2', 'B002AQP5MK', 'B005GTWCTM', 'B001LG940E', 'B0033HPPIO']\n",
        "\n",
        "for pid in pid_test:\n",
        "  row = [pid, ]\n",
        "  df = data.loc[data['ProductId'] == pid]\n",
        "  df2 = meta_data.loc[meta_data['asin'] == pid]\n",
        "  row += [df2['title'].values[0],]\n",
        "  x_tr = np.array(df['cleaned_text'])\n",
        "\n",
        "  #prepare a tokenizer for reviews on training data\n",
        "  x_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
        "  x_tokenizer.fit_on_texts(list(x_tr))\n",
        "\n",
        "  #convert text sequences into integer sequences\n",
        "  x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr)\n",
        "\n",
        "  #padding zero upto maximum length\n",
        "  x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
        "\n",
        "  #size of vocabulary ( +1 for padding token)\n",
        "  x_voc   =  x_tokenizer.num_words + 1\n",
        "\n",
        "  sums = []\n",
        "  sents = []\n",
        "  for i in range(len(x_tr)):\n",
        "    try:\n",
        "      s = decode_sequence(x_tr[i].reshape(1,max_text_len))\n",
        "    except:\n",
        "      print(\"Key Error occurred\")\n",
        "      continue\n",
        "    if pred_sentiment(seq2text(x_tr[i])) == 'Positive':\n",
        "      sents += [1, ]\n",
        "    else :\n",
        "      sents += [0, ]\n",
        "#    print(\"Review:\",seq2text(x_tr[i]))\n",
        "#    print(\"Predicted summary:\",s)\n",
        "    sums += [s,]\n",
        "#    print(\"\\n\")\n",
        "  row += [\". \".join(sums),]\n",
        "  row += [df['Score'].sum()/len(df),]\n",
        "  if sents.count(1) > sents.count(0):\n",
        "    row += [1,]\n",
        "  else:\n",
        "    row += [0,]\n",
        "  res_df = res_df.append({'pid':row[0], 'title': row[1], 'summaries':summarize((row[2]), ratio = 0.01).replace('\\n', ' '), 'avg_rating':row[3], 'sentiment':row[4]},ignore_index=True)\n",
        "  print(res_df.loc[j])\n",
        "  j += 1\n",
        "#  print(res_df)\n",
        "\n",
        "print(res_df)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pid                                                                                                                                                                                                        B000CQE3NM\n",
            "title         Stash Tea Moroccan Mint Green Tea 20 Count Box of Tea Bags (Pack of 6), Tea Bags Individually Wrapped in Foil (packaging may vary), Medium Caffeine Tea, Green Tea Blended with Mint, Drink Hot or Iced\n",
            "summaries                                                                                                                                                                                                            \n",
            "avg_rating                                                                                                                                                                                                        NaN\n",
            "sentiment                                                                                                                                                                                                           0\n",
            "Name: 0, dtype: object\n",
            "pid                                                                  B001L4JH5I\n",
            "title         Pamela's Products Gluten-free Bread Mix, 4-Pound Bags (Pack of 3)\n",
            "summaries                                                  great cup of coffee.\n",
            "avg_rating                                                              4.62088\n",
            "sentiment                                                                     1\n",
            "Name: 1, dtype: object\n",
            "pid                                                                                  B003EM7J9Q\n",
            "title         Lowrey's Bacon Curls Microwave Pork Rinds (Chicharrones), Hot & Spicy, 1.75 Ounce\n",
            "summaries                                best tasting protein drink ever. great tasting coffee.\n",
            "avg_rating                                                                              4.05842\n",
            "sentiment                                                                                     1\n",
            "Name: 2, dtype: object\n",
            "pid                                                                                                                                                                  B000CQID2Y\n",
            "title         Stash Tea Chamomile Herbal Tea 20 Count (Pack of 6), Premium Herbal Tisane, Sweet Soothing Herbal Tea, Enjoy Chamomile Tea Hot or Iced, Ideal to Drink at Bedtime\n",
            "summaries                                                                                                                                                                      \n",
            "avg_rating                                                                                                                                                                  NaN\n",
            "sentiment                                                                                                                                                                     0\n",
            "Name: 3, dtype: object\n",
            "pid                                                                                             B005K4Q1T0\n",
            "title                                          Grove Square Hot Cocoa Dark Chocolate, 24 Single Serve Cups\n",
            "summaries     tastes great and it is my coffee drink from. great if you like coffee. great tasting coffee.\n",
            "avg_rating                                                                                         3.95988\n",
            "sentiment                                                                                                1\n",
            "Name: 4, dtype: object\n",
            "pid                                                                        B000DZFMEQ\n",
            "title         Pamela's Products Gluten Free, Bread Mix, 19-Ounce Packages (Pack of 6)\n",
            "summaries         great tasting coffee. good coffee but does not like the taste says.\n",
            "avg_rating                                                                    4.61017\n",
            "sentiment                                                                           1\n",
            "Name: 5, dtype: object\n",
            "pid                      B001GL6GBE\n",
            "title         Power Crunch, 12 bars\n",
            "summaries       coffee great price.\n",
            "avg_rating                  4.61972\n",
            "sentiment                         1\n",
            "Name: 6, dtype: object\n",
            "pid                                                                                                                                                                                    B003CK7O36\n",
            "title         Stash Tea Ginger Breakfast Black Tea 18 Count Tea Bags in Foil (Pack of 6) (Packaging May Vary) Individual Black Tea Bags for Use in Teapots Mugs or Cups, Brew Hot Tea or Iced Tea\n",
            "summaries                                                                                                                                                                                        \n",
            "avg_rating                                                                                                                                                                                    NaN\n",
            "sentiment                                                                                                                                                                                       0\n",
            "Name: 7, dtype: object\n",
            "pid                                                                                   B003QNJYXM\n",
            "title                                    5 Hour Energy Extra Strength Energy Shots, Berry, 12 pk\n",
            "summaries     very good tasting coffee. great flavored coffee. the best coffee have ever tasted.\n",
            "avg_rating                                                                               4.19571\n",
            "sentiment                                                                                      1\n",
            "Name: 8, dtype: object\n",
            "pid                                                                B000ZSZ5S4\n",
            "title         Blue Diamond Almonds, Bold Salt & Vinegar, 6 Ounce (Pack of 12)\n",
            "summaries                                  great tasting coffee decent value.\n",
            "avg_rating                                                            4.67251\n",
            "sentiment                                                                   1\n",
            "Name: 9, dtype: object\n",
            "pid                                                                                                                  B001EO5Y8Y\n",
            "title         Green Mountain Coffee, Dark Magic (Extra Bold), K-Cup Portion Pack for Keurig K-Cup Brewers 24-Count  (Pack of 2)\n",
            "summaries                                                 great taste and good for you. good coffee but did not like the taste.\n",
            "avg_rating                                                                                                              4.49071\n",
            "sentiment                                                                                                                     1\n",
            "Name: 10, dtype: object\n",
            "pid                                                                                                                      B000CQC08C\n",
            "title         Stash Tea Premium Green Tea, 20 Count Tea Bags (Pack of 6) Medium Caffiene Tea, Japanese Style Green Tea, Hot or Iced\n",
            "summaries                                                                                                                          \n",
            "avg_rating                                                                                                                      NaN\n",
            "sentiment                                                                                                                         0\n",
            "Name: 11, dtype: object\n",
            "pid                                                                      B0039ZOZ86\n",
            "title         Gourmet Basics Smart Fries Original KC BBQ, 3-Ounce Bags (Pack of 12)\n",
            "summaries                                      tastes great but has msg and flavor.\n",
            "avg_rating                                                                  4.14765\n",
            "sentiment                                                                         1\n",
            "Name: 12, dtype: object\n",
            "pid                                                                                                                                          B005K4Q37A\n",
            "title                                                                                Grove Square Cappuccino, Caramel, 12 Single Serve Cups (Pack of 3)\n",
            "summaries     these flavor good if you like flavored coffee. good cup of coffee. great flavored coffee. great flavored coffee. good taste not so great.\n",
            "avg_rating                                                                                                                                      3.81701\n",
            "sentiment                                                                                                                                             1\n",
            "Name: 13, dtype: object\n",
            "pid                                   B000REI2X6\n",
            "title                     Belly Flops® 1 Lb. Bag\n",
            "summaries     great if you like flavored coffee.\n",
            "avg_rating                               4.05291\n",
            "sentiment                                      1\n",
            "Name: 14, dtype: object\n",
            "pid                                                                                                                                                                                                             B000PDY3P0\n",
            "title                                                                                                                                        4100 Great Northern Popcorn 4 Ounce Premium Popcorn Portion Packs, Case of 24\n",
            "summaries     with my coffee and great way to other flavor to be that even taste. very good coffee but the best flavor. good lollipops but not great coffee too bitter in my house. best flavored coffee have ever tasted.\n",
            "avg_rating                                                                                                                                                                                                         4.35391\n",
            "sentiment                                                                                                                                                                                                                1\n",
            "Name: 15, dtype: object\n",
            "pid                                                                                                            B005ZBZLSU\n",
            "title         San Francisco Bay OneCup, French Roast, 12 Count- Single Serve Coffee, Compatible with Keurig K-cup Brewers\n",
            "summaries                                                  delicious coffee that tastes like aroma. great tasting coffee.\n",
            "avg_rating                                                                                                        4.34672\n",
            "sentiment                                                                                                               1\n",
            "Name: 16, dtype: object\n",
            "pid                                        B002GJ9JY6\n",
            "title         Powdered Peanut Butter - 12 Pack/6.5 oz\n",
            "summaries                                            \n",
            "avg_rating                                        NaN\n",
            "sentiment                                           0\n",
            "Name: 17, dtype: object\n",
            "pid                                                                                     B006N3HYYS\n",
            "title         Coffee People Black Tiger Dark Roast, 24-Count K-Cup Portion Pack for Keurig Brewers\n",
            "summaries                                                         great coffee at very good price.\n",
            "avg_rating                                                                                 4.31447\n",
            "sentiment                                                                                        1\n",
            "Name: 18, dtype: object\n",
            "pid                                                                                                                                                                 B000CQIDHY\n",
            "title         Stash Tea English Breakfast Black Tea, 20 Count Tea Bags in Foil (Pack of 6) Individual Black Tea Bags for Use in Teapots Mugs or Cups, Brew Hot Tea or Iced Tea\n",
            "summaries                                                                                                                                                                     \n",
            "avg_rating                                                                                                                                                                 NaN\n",
            "sentiment                                                                                                                                                                    0\n",
            "Name: 19, dtype: object\n",
            "pid                                                                                B001E5E3JY\n",
            "title         SweetLeaf Sweet Drops Liquid Stevia Sweetener, SteviaClear, 4 Ounce (Pack of 2)\n",
            "summaries                                  good not great but ok if you like flavored coffee.\n",
            "avg_rating                                                                            4.17424\n",
            "sentiment                                                                                   1\n",
            "Name: 20, dtype: object\n",
            "pid                                                                                                        B000F6SNPS\n",
            "title         Good Earth Herbal Tea, Sweet & Spicy, Caffeine Free, 18 Count Tea Bags (Pack of 6) (Packaging May Vary)\n",
            "summaries                                                                                       great tasting coffee.\n",
            "avg_rating                                                                                                    3.68531\n",
            "sentiment                                                                                                           1\n",
            "Name: 21, dtype: object\n",
            "pid                                                                                                                    B005ZBZLT4\n",
            "title                                                   San Francisco Bay OneCup, Fog Chaser, 12 Single Serve Coffees (Pack of 3)\n",
            "summaries     great taste but loved it. tasty but not as good as dark rich cups. good cup of coffee. great taste but much better.\n",
            "avg_rating                                                                                                                4.36364\n",
            "sentiment                                                                                                                       1\n",
            "Name: 22, dtype: object\n",
            "pid                                                                                                                                                              B000CQIDHO\n",
            "title         Stash Tea Strawberry Pomegranate Red Tea 18 Count Tea Bags in Foil (Pack of 6) Individual Red Tea Bags, Use in Teapots Mugs or Cups, Brew Hot Tea or Iced Tea\n",
            "summaries                                                                                                                                            good blend nice taste.\n",
            "avg_rating                                                                                                                                                          4.50588\n",
            "sentiment                                                                                                                                                                 1\n",
            "Name: 23, dtype: object\n",
            "pid                                                      B0008IT4OM\n",
            "title         Chocmod Truffettes de France Natural Truffles 2.2 lbs\n",
            "summaries                                      great tasting snack.\n",
            "avg_rating                                                  3.94156\n",
            "sentiment                                                         1\n",
            "Name: 24, dtype: object\n",
            "pid                                                                                                                                                                                              B003CK2BQG\n",
            "title         Stash Tea Mojito Mint Green Tea & Matcha Blend 18 Count Tea Bags in Foil (Pack of 6) (Packaging May Vary) Individual Green Tea Bags for Use in Teapots Mugs or Cups, Brew Hot Tea or Iced Tea\n",
            "summaries                                                                                                                                                                 good if you like flavored coffee.\n",
            "avg_rating                                                                                                                                                                                          4.47573\n",
            "sentiment                                                                                                                                                                                                 1\n",
            "Name: 25, dtype: object\n",
            "pid                                                             B000ESLJ6C\n",
            "title         Pero Instant Natural Beverage, 7-Ounce Canisters (Pack of 6)\n",
            "summaries                                         great tasting of coffee.\n",
            "avg_rating                                                         4.56115\n",
            "sentiment                                                                1\n",
            "Name: 26, dtype: object\n",
            "pid                                                          B000HDK0DC\n",
            "title         YumEarth Organic Lollipops, Assorted Flavors, 5 Pound Bag\n",
            "summaries                  great tasting coffee. great flavored coffee.\n",
            "avg_rating                                                      4.65683\n",
            "sentiment                                                             1\n",
            "Name: 27, dtype: object\n",
            "pid                                                                                      B001EYUE5M\n",
            "title         Green Mountain Coffee Breakfast Blend for Keurig Brewers, 24-Count K-Cups (Pack of 2)\n",
            "summaries                               good enough for cup of coffee lovers. great instant coffee.\n",
            "avg_rating                                                                                  4.25726\n",
            "sentiment                                                                                         1\n",
            "Name: 28, dtype: object\n",
            "pid                                                     B005DFL4PM\n",
            "title         Bell Plantation PB2 with Premium Chocolate, 16-Ounce\n",
            "summaries                         good decaf with flavored coffee.\n",
            "avg_rating                                                 4.48718\n",
            "sentiment                                                        1\n",
            "Name: 29, dtype: object\n",
            "pid                                                              B001CWX7EG\n",
            "title         Glutino Gluten Free Pretzel Sticks, 8-Ounce Bags (Pack of 12)\n",
            "summaries                                               good cup of coffee.\n",
            "avg_rating                                                          4.78912\n",
            "sentiment                                                                 1\n",
            "Name: 30, dtype: object\n",
            "pid                                                                                  B000DZDJ0K\n",
            "title         Pamela's Products Gluten Free Baking & Pancake Mix, 24-Ounce Packages (Pack of 6)\n",
            "summaries                                                              good flavor great taste.\n",
            "avg_rating                                                                              4.79856\n",
            "sentiment                                                                                     1\n",
            "Name: 31, dtype: object\n",
            "pid                                                                                                                                                                        B000CQBZOW\n",
            "title         Stash Tea Wild Raspberry Hibiscus Herbal Tea 20 Count Tea Bags in Foil (Pack of 6) Individual Herbal Tea Bags for Use in Teapots Mugs or Cups, Brew Hot Tea or Iced Tea\n",
            "summaries                                                                                                                                                                            \n",
            "avg_rating                                                                                                                                                                        NaN\n",
            "sentiment                                                                                                                                                                           0\n",
            "Name: 32, dtype: object\n",
            "pid                                                                                                                        B004SRH2B6\n",
            "title                                                     ZICO Pure Premium Coconut Water, Natural, 33.8 fl oz Container (Count of 6)\n",
            "summaries     the best cup of coffee flavor. expired flavor and good amount of coffee. great tasting coffee. good coffee great price.\n",
            "avg_rating                                                                                                                    3.67105\n",
            "sentiment                                                                                                                           1\n",
            "Name: 33, dtype: object\n",
            "pid                                                B005GX00BK\n",
            "title         Lavazza Crema e Gusto Espresso 8.8oz(Pack of 6)\n",
            "summaries                              great flavored coffee.\n",
            "avg_rating                                            4.40625\n",
            "sentiment                                                   1\n",
            "Name: 34, dtype: object\n",
            "pid                                                                                                                                   B007TJGZ5E\n",
            "title         Green Mountain Coffee Roasters Nantucket Blend, Keurig Single-Serve K-Cup Pods, Medium Roast Coffee, 96 Count (Packaging May Vary)\n",
            "summaries                                                                                                            great coffee at good price.\n",
            "avg_rating                                                                                                                               4.41176\n",
            "sentiment                                                                                                                                      1\n",
            "Name: 35, dtype: object\n",
            "pid                                                                                       B008ZRKZSM\n",
            "title                                                            Pb2 Powdered Peanut Butter - 6.5 Oz\n",
            "summaries     pretty good no quality coffee drink. very good tasting coffee. good coffee bad flavor.\n",
            "avg_rating                                                                                   4.46774\n",
            "sentiment                                                                                          1\n",
            "Name: 36, dtype: object\n",
            "pid                                                                                                                                                    B000CQG8KS\n",
            "title         Stash Tea Peach Black Tea 20 Count Tea Bags in Foil (Pack of 6) Individual Black Tea Bags for Use in Teapots Mugs or Cups, Brew Hot Tea or Iced Tea\n",
            "summaries                                                                                                                                   great tasting coffee.\n",
            "avg_rating                                                                                                                                                4.35407\n",
            "sentiment                                                                                                                                                       1\n",
            "Name: 37, dtype: object\n",
            "pid                                                                                                                                                        B000CQC05K\n",
            "title         Stash Tea Yumberry Blackcurrant Tea 20 Tea Bags in Foil (Pack of 6) Individual Black Tea Bags for Use in Teapots Mugs or Cups, Brew Hot Tea or Iced Tea\n",
            "summaries                                                                                                                                                            \n",
            "avg_rating                                                                                                                                                        NaN\n",
            "sentiment                                                                                                                                                           0\n",
            "Name: 38, dtype: object\n",
            "pid                                                                            B0058AMYTC\n",
            "title         Kettle Brand Potato Chips, Jalapeno, Single-Serve 1 Ounce Bags (Pack of 72)\n",
            "summaries         great if you like flavored coffee. tastes good but has flavored coffee.\n",
            "avg_rating                                                                        4.00465\n",
            "sentiment                                                                               1\n",
            "Name: 39, dtype: object\n",
            "pid                                                                                                                                                                                                        B005HG9ESG\n",
            "title         Essentia Water; 12, 1-Liter Bottles; Ionized Alkaline Bottled Water; Electrolytes for Taste; Better Rehydration; pH 9.5 or Higher; Pure Drinking Water; For the Doers, the Believers, the Overachievers\n",
            "summaries                                                                                                                              good coffee bad flavor. great if you love strong coffee. great tasting coffee.\n",
            "avg_rating                                                                                                                                                                                                    3.90956\n",
            "sentiment                                                                                                                                                                                                           1\n",
            "Name: 40, dtype: object\n",
            "pid                                                                                                                       B000GAT6NG\n",
            "title         Nutiva Organic, Cold-Pressed, Unrefined, Virgin Coconut Oil from Fresh, non-GMO, Sustainably Farmed Coconuts, 54-ounce\n",
            "summaries                                       great coffee for cups. great tasting coffee but expensive. great taste better to me.\n",
            "avg_rating                                                                                                                   4.80206\n",
            "sentiment                                                                                                                          1\n",
            "Name: 41, dtype: object\n",
            "pid                                                                                                                                                                                                       B000CQIDHE\n",
            "title         Stash Tea Licorice Spice Herbal Tea 20 Count Tea Bags in Foil (Pack of 6), Tea Bags Individually Wrapped in Foil (packaging may vary), Naturally Sweet Herbal Tisane, Zero Caffeine, Drink Hot or Iced\n",
            "summaries                                                                                                                                                                                                           \n",
            "avg_rating                                                                                                                                                                                                       NaN\n",
            "sentiment                                                                                                                                                                                                          0\n",
            "Name: 42, dtype: object\n",
            "pid                                                                     B000WB1YSE\n",
            "title         Kirkland Ito En Matcha Blend Japanese Green Tea-100 ct 1.5g tea bags\n",
            "summaries                                                    great tasting coffee.\n",
            "avg_rating                                                                 4.28025\n",
            "sentiment                                                                        1\n",
            "Name: 43, dtype: object\n",
            "pid                                                                                                                                                           B0012BUR8Q\n",
            "title         Stash Tea Acai Berry Herbal Tea 18 Count Tea Bags in Foil (Pack of 6) Individual Herbal Tea Bags for Use in Teapots Mugs or Cups, Brew Hot Tea or Iced Tea\n",
            "summaries                                                                                                                                                               \n",
            "avg_rating                                                                                                                                                           NaN\n",
            "sentiment                                                                                                                                                              0\n",
            "Name: 44, dtype: object\n",
            "pid                                                                                                 B0098WV8F2\n",
            "title         Bell Plantation PB2 Powdered Peanut Butter and PB2 with Premium Chocolate, 6.5 Ounce (Pack of 2)\n",
            "summaries                                       great taste poor price. tastes good stuff one of my favorites.\n",
            "avg_rating                                                                                              4.3972\n",
            "sentiment                                                                                                    1\n",
            "Name: 45, dtype: object\n",
            "pid                                                                                    B002AQP5MK\n",
            "title         Betty Crocker Baking Mix, Gluten Free Brownie Mix, Chocolate, 16 Oz Box (Pack of 6)\n",
            "summaries                                                   good coffee little brooklyn is great.\n",
            "avg_rating                                                                                4.42963\n",
            "sentiment                                                                                       1\n",
            "Name: 46, dtype: object\n",
            "pid                                                           B005GTWCTM\n",
            "title         Lavazza 2 Pack Crema E Gusto Ground Coffee 8.8oz/250g Each\n",
            "summaries                                                               \n",
            "avg_rating                                                           NaN\n",
            "sentiment                                                              0\n",
            "Name: 47, dtype: object\n",
            "pid                                                                                        B001LG940E\n",
            "title                           The Switch Sparkling Juice, Black Cherry, 8- Fl. Oz Cans (Pack of 24)\n",
            "summaries     great tasting coffee in. tastes great but it is instant coffee. great taste and flavor.\n",
            "avg_rating                                                                                    3.70845\n",
            "sentiment                                                                                           1\n",
            "Name: 48, dtype: object\n",
            "pid                                                                                                                  B0033HPPIO\n",
            "title         Donut House Collection Coffee Chocolate Glazed Donut Keurig Single-Serve K-Cup Pods, Light Roast Coffee, 24 Count\n",
            "summaries                                                                                                  smooth coffee taste.\n",
            "avg_rating                                                                                                              3.56604\n",
            "sentiment                                                                                                                     1\n",
            "Name: 49, dtype: object\n",
            "           pid  ... sentiment\n",
            "0   B000CQE3NM  ...         0\n",
            "1   B001L4JH5I  ...         1\n",
            "2   B003EM7J9Q  ...         1\n",
            "3   B000CQID2Y  ...         0\n",
            "4   B005K4Q1T0  ...         1\n",
            "5   B000DZFMEQ  ...         1\n",
            "6   B001GL6GBE  ...         1\n",
            "7   B003CK7O36  ...         0\n",
            "8   B003QNJYXM  ...         1\n",
            "9   B000ZSZ5S4  ...         1\n",
            "10  B001EO5Y8Y  ...         1\n",
            "11  B000CQC08C  ...         0\n",
            "12  B0039ZOZ86  ...         1\n",
            "13  B005K4Q37A  ...         1\n",
            "14  B000REI2X6  ...         1\n",
            "15  B000PDY3P0  ...         1\n",
            "16  B005ZBZLSU  ...         1\n",
            "17  B002GJ9JY6  ...         0\n",
            "18  B006N3HYYS  ...         1\n",
            "19  B000CQIDHY  ...         0\n",
            "20  B001E5E3JY  ...         1\n",
            "21  B000F6SNPS  ...         1\n",
            "22  B005ZBZLT4  ...         1\n",
            "23  B000CQIDHO  ...         1\n",
            "24  B0008IT4OM  ...         1\n",
            "25  B003CK2BQG  ...         1\n",
            "26  B000ESLJ6C  ...         1\n",
            "27  B000HDK0DC  ...         1\n",
            "28  B001EYUE5M  ...         1\n",
            "29  B005DFL4PM  ...         1\n",
            "30  B001CWX7EG  ...         1\n",
            "31  B000DZDJ0K  ...         1\n",
            "32  B000CQBZOW  ...         0\n",
            "33  B004SRH2B6  ...         1\n",
            "34  B005GX00BK  ...         1\n",
            "35  B007TJGZ5E  ...         1\n",
            "36  B008ZRKZSM  ...         1\n",
            "37  B000CQG8KS  ...         1\n",
            "38  B000CQC05K  ...         0\n",
            "39  B0058AMYTC  ...         1\n",
            "40  B005HG9ESG  ...         1\n",
            "41  B000GAT6NG  ...         1\n",
            "42  B000CQIDHE  ...         0\n",
            "43  B000WB1YSE  ...         1\n",
            "44  B0012BUR8Q  ...         0\n",
            "45  B0098WV8F2  ...         1\n",
            "46  B002AQP5MK  ...         1\n",
            "47  B005GTWCTM  ...         0\n",
            "48  B001LG940E  ...         1\n",
            "49  B0033HPPIO  ...         1\n",
            "\n",
            "[50 rows x 5 columns]\n",
            "CPU times: user 29min 26s, sys: 42.2 s, total: 30min 8s\n",
            "Wall time: 29min 28s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAfIgRm2a9Yt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "4d5b255d-f0ba-4f1e-e821-c798d555c2a2"
      },
      "source": [
        "res_df.loc[0]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pid                                                                                                                                                                                                        B000CQE3NM\n",
              "title         Stash Tea Moroccan Mint Green Tea 20 Count Box of Tea Bags (Pack of 6), Tea Bags Individually Wrapped in Foil (packaging may vary), Medium Caffeine Tea, Green Tea Blended with Mint, Drink Hot or Iced\n",
              "summaries                                                                                                                                                                                                            \n",
              "avg_rating                                                                                                                                                                                                        NaN\n",
              "sentiment                                                                                                                                                                                                           0\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8TpAolVc_B4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d32c1cfa-e4df-44e1-ae35-f1805fb7429a"
      },
      "source": [
        "new_js = res_df.to_json ('result.json', orient='records')\n",
        "print(new_js)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}